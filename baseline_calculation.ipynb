{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "162b83a4-5aff-4abe-b084-1626ca16c2d3",
   "metadata": {},
   "source": [
    "# Random Forest baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de00541d-8ebd-4d0b-84d0-cf0831dcfeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random_state=0 - Illicit F1-score: 0.8253\n",
      "Run with random_state=1 - Illicit F1-score: 0.8215\n",
      "Run with random_state=2 - Illicit F1-score: 0.8255\n",
      "Run with random_state=3 - Illicit F1-score: 0.8235\n",
      "Run with random_state=4 - Illicit F1-score: 0.8212\n",
      "\n",
      "Final RF Baseline - Median Illicit F1-score over 5 runs: 0.8235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Step 1: Load data\n",
    "features_df = pd.read_csv('elliptic_txs_features.csv', header=None)\n",
    "classes_df  = pd.read_csv('elliptic_txs_classes.csv')\n",
    "\n",
    "# Step 2: Process columns\n",
    "features_df.columns = ['txId', 'time_step'] + [f'feature_{i}' for i in range(features_df.shape[1] - 2)]\n",
    "classes_df.columns = ['txId', 'class']\n",
    "\n",
    "# Step 3: Clean txId\n",
    "features_df['txId'] = features_df['txId'].astype(str).str.strip()\n",
    "classes_df['txId'] = classes_df['txId'].astype(str).str.strip()\n",
    "\n",
    "# Step 4: Process labels\n",
    "classes_df['class'] = classes_df['class'].replace('unknown', np.nan)\n",
    "classes_df['class'] = classes_df['class'].astype(float)\n",
    "\n",
    "# Step 5: Merge\n",
    "data_df = pd.merge(features_df, classes_df, on='txId')\n",
    "data_df['time_step'] = data_df['time_step'].astype(int)\n",
    "labeled_df = data_df[data_df['class'].isin([1, 2])]\n",
    "\n",
    "# Step 6: Split train/test\n",
    "train_df = labeled_df[labeled_df['time_step'] <= 34]\n",
    "test_df  = labeled_df[labeled_df['time_step'] >= 35]\n",
    "\n",
    "X_train = train_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_train = (train_df['class'] == 1).astype(int)\n",
    "\n",
    "X_test = test_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_test = (test_df['class'] == 1).astype(int)\n",
    "\n",
    "# Step 7: Run RF 5 times with different random seeds\n",
    "f1_scores = []\n",
    "\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "for seed in seeds:\n",
    "    rf_clf = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf_clf.fit(X_train, y_train)\n",
    "    y_pred = rf_clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"Run with random_state={seed} - Illicit F1-score: {f1:.4f}\")\n",
    "\n",
    "# Step 8: Median F1-score\n",
    "median_f1 = np.median(f1_scores)\n",
    "print(\"\\nFinal RF Baseline - Median Illicit F1-score over 5 runs: {:.4f}\".format(median_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69fbbd-4b6e-4684-b440-a6ab41ce7d1a",
   "metadata": {},
   "source": [
    "# XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3dbdf4f-44cf-485e-8386-102982131cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded labeled CSV rows: 46564\n",
      "Unique time_steps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "Label distribution:\n",
      " class\n",
      "2.0    42019\n",
      "1.0     4545\n",
      "Name: count, dtype: int64\n",
      "Train samples: 29894\n",
      "Test samples: 16670\n",
      "Train label dist:\n",
      " class\n",
      "2.0    26432\n",
      "1.0     3462\n",
      "Name: count, dtype: int64\n",
      "Test label dist:\n",
      " class\n",
      "2.0    15587\n",
      "1.0     1083\n",
      "Name: count, dtype: int64\n",
      "Run with random_state=0 - Illicit F1-score: 0.8014\n",
      "Run with random_state=1 - Illicit F1-score: 0.8014\n",
      "Run with random_state=2 - Illicit F1-score: 0.8014\n",
      "Run with random_state=3 - Illicit F1-score: 0.8014\n",
      "Run with random_state=4 - Illicit F1-score: 0.8014\n",
      "\n",
      "Final XGBoost Baseline - Median Illicit F1-score over 5 runs: 0.8014\n"
     ]
    }
   ],
   "source": [
    "# --- XGBoost Baseline: 5-run Median Version ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Step 1: Load labeled data\n",
    "labeled_df = pd.read_csv('elliptic_txs_features_labeled.csv')\n",
    "\n",
    "# Debug\n",
    "print(\"Loaded labeled CSV rows:\", labeled_df.shape[0])\n",
    "print(\"Unique time_steps:\", sorted(labeled_df['time_step'].unique()))\n",
    "print(\"Label distribution:\\n\", labeled_df['class'].value_counts())\n",
    "\n",
    "# Step 2: Split train/test\n",
    "train_df = labeled_df[labeled_df['time_step'] <= 34]\n",
    "test_df  = labeled_df[labeled_df['time_step'] >= 35]\n",
    "\n",
    "print(\"Train samples:\", len(train_df))\n",
    "print(\"Test samples:\", len(test_df))\n",
    "print(\"Train label dist:\\n\", train_df['class'].value_counts())\n",
    "print(\"Test label dist:\\n\", test_df['class'].value_counts())\n",
    "\n",
    "# Step 3: Prepare features and labels\n",
    "X_train = train_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_train = (train_df['class'] == 1).astype(int)\n",
    "\n",
    "X_test = test_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_test = (test_df['class'] == 1).astype(int)\n",
    "\n",
    "# Step 4: Run XGBoost 5 times with different random states\n",
    "f1_scores = []\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "for seed in seeds:\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        tree_method='hist',\n",
    "        # use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    xgb_clf.fit(X_train, y_train)\n",
    "    y_pred = xgb_clf.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"Run with random_state={seed} - Illicit F1-score: {f1:.4f}\")\n",
    "\n",
    "# Step 5: Median F1-score\n",
    "median_f1 = np.median(f1_scores)\n",
    "print(\"\\nFinal XGBoost Baseline - Median Illicit F1-score over 5 runs: {:.4f}\".format(median_f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea0b93-d9fd-4897-8b71-3fbd113cd40b",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b5076c2-7cf7-4eb3-b59d-f920919caa55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run with random_state=0 - Illicit F1-score: 0.4437\n",
      "Run with random_state=1 - Illicit F1-score: 0.4437\n",
      "Run with random_state=2 - Illicit F1-score: 0.4437\n",
      "Run with random_state=3 - Illicit F1-score: 0.4437\n",
      "Run with random_state=4 - Illicit F1-score: 0.4437\n",
      "\n",
      "Final Logistic Regression Baseline - Median Illicit F1-score over 5 runs: 0.4437\n"
     ]
    }
   ],
   "source": [
    "# --- Logistic Regression Baseline: 5-run Median Version ---\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Step 1: Load data\n",
    "features_df = pd.read_csv('elliptic_txs_features.csv', header=None)\n",
    "classes_df  = pd.read_csv('elliptic_txs_classes.csv')\n",
    "\n",
    "# Step 2: Assign column names\n",
    "features_df.columns = ['txId', 'time_step'] + [f'feature_{i}' for i in range(features_df.shape[1] - 2)]\n",
    "classes_df.columns = ['txId', 'class']\n",
    "\n",
    "# Step 3: Clean txId\n",
    "features_df['txId'] = features_df['txId'].astype(str).str.strip()\n",
    "classes_df['txId'] = classes_df['txId'].astype(str).str.strip()\n",
    "\n",
    "# Step 4: Clean class column\n",
    "classes_df['class'] = classes_df['class'].replace('unknown', np.nan)\n",
    "classes_df['class'] = classes_df['class'].astype(float)\n",
    "\n",
    "# Step 5: Merge and clean\n",
    "data_df = pd.merge(features_df, classes_df, on='txId')\n",
    "data_df['time_step'] = data_df['time_step'].astype(int)\n",
    "\n",
    "# Step 6: Keep labeled samples\n",
    "labeled_df = data_df[data_df['class'].isin([1, 2])]\n",
    "\n",
    "# Step 7: Split into train/test\n",
    "train_df = labeled_df[labeled_df['time_step'] <= 34]\n",
    "test_df  = labeled_df[labeled_df['time_step'] >= 35]\n",
    "\n",
    "X_train = train_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_train = (train_df['class'] == 1).astype(int)\n",
    "\n",
    "X_test = test_df.drop(columns=['txId', 'time_step', 'class'])\n",
    "y_test = (test_df['class'] == 1).astype(int)\n",
    "\n",
    "# Step 8: Train and evaluate with 5 different random seeds\n",
    "f1_scores = []\n",
    "seeds = [0, 1, 2, 3, 4]\n",
    "\n",
    "for seed in seeds:\n",
    "    lr_clf = LogisticRegression(max_iter=1000, solver='lbfgs', random_state=seed)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    y_pred = lr_clf.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"Run with random_state={seed} - Illicit F1-score: {f1:.4f}\")\n",
    "\n",
    "# Step 9: Median F1-score\n",
    "median_f1 = np.median(f1_scores)\n",
    "print(\"\\nFinal Logistic Regression Baseline - Median Illicit F1-score over 5 runs: {:.4f}\".format(median_f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5379dd-ce43-43b5-b7fa-c1d7c70c54a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd28d236-81a1-4c9f-bf93-f19ece62ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ef180-88e2-4707-b71a-42d794468780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eac2815-6840-438e-9c86-af1c903b9624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779b3f2-0fc0-4597-b1ca-b7bed7f1a9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83e8d4-0bc3-49bb-9872-fe845378e213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f90d54c-8261-4d38-b864-01b6ab77cd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10c5c3-bdfb-4f48-94c5-34fe2e308452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a506731-b372-4240-9fcc-b477690bd99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f5e14-d540-4d66-8402-2ea4fc31e164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43326024-892f-4510-a6fe-d8667b0ee6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdcb4c-22ed-4d1e-bb3b-7eae89f82198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0726a6-2c9c-4bf8-b3e5-cbdd373ffc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b846b4-bffb-4fd9-bc9b-ce18d49cd539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748e645-1f4a-41b9-873f-9a7c7cabc997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc0799-2cc7-4746-9e73-435224d2ba57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
