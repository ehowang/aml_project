{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded and merged successfully.\n",
      "Total transactions: 203769\n",
      "Class distribution:\n",
      "class\n",
      "unknown    157205\n",
      "licit       42019\n",
      "illicit      4545\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Starting Skip-GCN Classification Experiment ---\n",
      "Creating sparse adjacency matrix...\n",
      "Processing 234355 edges...\n",
      "Created sparse adjacency matrix with 468710 edges\n",
      "Normalizing sparse adjacency matrix...\n",
      "Training Skip-GCN model...\n",
      "Epoch 020 | Loss: 0.3159 | Train Acc: 0.9042\n",
      "Epoch 040 | Loss: 0.2518 | Train Acc: 0.9189\n",
      "Epoch 060 | Loss: 0.2189 | Train Acc: 0.9302\n",
      "Epoch 080 | Loss: 0.1971 | Train Acc: 0.9413\n",
      "Epoch 100 | Loss: 0.1805 | Train Acc: 0.9473\n",
      "Epoch 120 | Loss: 0.1675 | Train Acc: 0.9518\n",
      "Epoch 140 | Loss: 0.1580 | Train Acc: 0.9550\n",
      "Epoch 160 | Loss: 0.1524 | Train Acc: 0.9573\n",
      "Epoch 180 | Loss: 0.1443 | Train Acc: 0.9594\n",
      "Epoch 200 | Loss: 0.1407 | Train Acc: 0.9615\n",
      "GCN training finished in 70.12 seconds.\n",
      "\n",
      "Evaluating model performance on the test set...\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Licit       0.97      0.95      0.96     15587\n",
      "     Illicit       0.48      0.63      0.54      1083\n",
      "\n",
      "    accuracy                           0.93     16670\n",
      "   macro avg       0.73      0.79      0.75     16670\n",
      "weighted avg       0.94      0.93      0.94     16670\n",
      "\n",
      "F1 Score for Illicit class: 0.5446\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This script implements the Graph Convolutional Network (GCN) model described in the paper:\n",
    "# \"Anti-Money Laundering in Bitcoin: Experimenting with Graph Convolutional Networks for Financial Forensics\"\n",
    "#\n",
    "# This implementation uses the GCN as an end-to-end classifier, leveraging both the graph\n",
    "# structure and the node features to predict illicit vs. licit transactions. It specifically\n",
    "# implements the Skip-GCN architecture, which the paper found to be more performant.\n",
    "#\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import time\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "import os, random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True   # 100 % repeatable\n",
    "torch.backends.cudnn.benchmark = False      # ã€ƒ  (slower, but reproducible)\n",
    "\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "\n",
    "# --- 1. Data Loading and Preprocessing ---\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads the Elliptic dataset from CSV files, merges them, and performs\n",
    "    initial preprocessing.\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        features_df = pd.read_csv('data/elliptic_txs_features.csv', header=None)\n",
    "        edgelist_df = pd.read_csv('data/elliptic_txs_edgelist.csv')\n",
    "        classes_df = pd.read_csv('data/elliptic_txs_classes.csv')\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Please make sure the dataset files are in the same directory.\")\n",
    "        return None, None\n",
    "\n",
    "    # Name the feature columns for clarity\n",
    "    features_df.columns = ['txId', 'timestep'] + [f'feature_{i}' for i in range(165)]\n",
    "\n",
    "    # Map class labels to meaningful names\n",
    "    classes_df['class'] = classes_df['class'].map({'1': 'illicit', '2': 'licit', 'unknown': 'unknown'})\n",
    "\n",
    "    # Merge features and classes\n",
    "    data_df = pd.merge(features_df, classes_df, on='txId', how='left')\n",
    "    \n",
    "    # Sort by timestep for temporal split\n",
    "    data_df = data_df.sort_values('timestep').reset_index(drop=True)\n",
    "\n",
    "    print(\"Data loaded and merged successfully.\")\n",
    "    print(f\"Total transactions: {len(data_df)}\")\n",
    "    print(\"Class distribution:\")\n",
    "    print(data_df['class'].value_counts())\n",
    "    \n",
    "    return data_df, edgelist_df\n",
    "\n",
    "# --- 2. GCN Model Definition ---\n",
    "class SkipGCN(nn.Module):\n",
    "    \"\"\"\n",
    "    A 2-layer Skip-Graph Convolutional Network (Skip-GCN) as described in the paper.\n",
    "    This variant adds a skip connection from the input features to the final output layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_features, n_hidden, n_classes, dropout_rate=0.5):\n",
    "        super(SkipGCN, self).__init__()\n",
    "        self.gc1 = nn.Linear(n_features, n_hidden)\n",
    "        self.gc2 = nn.Linear(n_hidden, n_classes)\n",
    "        self.skip_layer = nn.Linear(n_features, n_classes, bias=False) # Skip connection\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        \"\"\"\n",
    "        Forward pass for the Skip-GCN.\n",
    "        adj: The normalized adjacency matrix (sparse).\n",
    "        x: The node feature matrix.\n",
    "        \"\"\"\n",
    "        # First GCN layer - use sparse matrix multiplication\n",
    "        h1 = F.relu(self.gc1(torch.sparse.mm(adj, x)))\n",
    "        h1_d = self.dropout(h1)\n",
    "        \n",
    "        # Second GCN layer - use sparse matrix multiplication\n",
    "        gcn_out = self.gc2(torch.sparse.mm(adj, h1_d))\n",
    "        \n",
    "        # Skip connection from original features\n",
    "        skip_out = self.skip_layer(x)\n",
    "        \n",
    "        # Combine GCN path and skip path\n",
    "        logits = gcn_out + skip_out\n",
    "        \n",
    "        return F.log_softmax(logits, dim=1)\n",
    "\n",
    "def normalize_adjacency_matrix_sparse(adj_sparse, n_nodes):\n",
    "    \"\"\"\n",
    "    Computes the symmetrically normalized adjacency matrix for sparse tensors.\n",
    "    A_hat = D^{-1/2} * (A + I) * D^{-1/2}\n",
    "    \"\"\"\n",
    "    print(\"Normalizing sparse adjacency matrix...\")\n",
    "    \n",
    "    # Add self-loops to sparse matrix\n",
    "    self_loop_indices = torch.arange(n_nodes).unsqueeze(0).repeat(2, 1)\n",
    "    self_loop_values = torch.ones(n_nodes)\n",
    "    self_loops = torch.sparse_coo_tensor(self_loop_indices, self_loop_values, (n_nodes, n_nodes))\n",
    "    \n",
    "    # Combine adjacency matrix with self-loops\n",
    "    adj_with_selfloops = adj_sparse + self_loops\n",
    "    adj_with_selfloops = adj_with_selfloops.coalesce()\n",
    "    \n",
    "    # Calculate degree matrix\n",
    "    row_sum = torch.sparse.sum(adj_with_selfloops, dim=1).to_dense()\n",
    "    d_inv_sqrt = torch.pow(row_sum, -0.5)\n",
    "    d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.\n",
    "    \n",
    "    # Create sparse diagonal matrix for normalization\n",
    "    diag_indices = torch.arange(n_nodes).unsqueeze(0).repeat(2, 1)\n",
    "    d_mat_inv_sqrt_sparse = torch.sparse_coo_tensor(diag_indices, d_inv_sqrt, (n_nodes, n_nodes))\n",
    "    \n",
    "    # Normalize: D^{-1/2} * A * D^{-1/2}\n",
    "    normalized = torch.sparse.mm(d_mat_inv_sqrt_sparse, adj_with_selfloops)\n",
    "    normalized = torch.sparse.mm(normalized, d_mat_inv_sqrt_sparse)\n",
    "    \n",
    "    return normalized.coalesce()\n",
    "\n",
    "# --- 3. Model Training and Evaluation ---\n",
    "def run_gcn_experiment(data_df, edgelist_df):\n",
    "    \"\"\"\n",
    "    Sets up the data, trains the Skip-GCN model, and evaluates its performance.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Starting Skip-GCN Classification Experiment ---\")\n",
    "    \n",
    "    # --- Data Preparation ---\n",
    "    # Map txId to an index for matrix construction\n",
    "    txid_to_idx = {txid: i for i, txid in enumerate(data_df['txId'])}\n",
    "    n_nodes = len(data_df)\n",
    "    \n",
    "    # Scale features (exclude the class column which is the last column)\n",
    "    features = data_df.iloc[:, 2:-1].values  # Exclude class column\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sparse adjacency matrix using COO format\n",
    "    print(\"Creating sparse adjacency matrix...\")\n",
    "    print(f\"Processing {len(edgelist_df)} edges...\")\n",
    "    \n",
    "    # More memory-efficient edge processing\n",
    "    src_indices = []\n",
    "    tgt_indices = []\n",
    "    \n",
    "    for _, row in edgelist_df.iterrows():\n",
    "        src_idx = txid_to_idx.get(row['txId1'])\n",
    "        tgt_idx = txid_to_idx.get(row['txId2'])\n",
    "        if src_idx is not None and tgt_idx is not None:\n",
    "            src_indices.extend([src_idx, tgt_idx])\n",
    "            tgt_indices.extend([tgt_idx, src_idx])  # Make symmetric\n",
    "    \n",
    "    if src_indices:\n",
    "        edge_indices = torch.LongTensor([src_indices, tgt_indices])\n",
    "        edge_values = torch.ones(len(src_indices))\n",
    "        adj_sparse = torch.sparse_coo_tensor(edge_indices, edge_values, (n_nodes, n_nodes))\n",
    "        print(f\"Created sparse adjacency matrix with {len(src_indices)} edges\")\n",
    "    else:\n",
    "        # Create empty sparse matrix if no edges\n",
    "        edge_indices = torch.LongTensor([[0], [0]])\n",
    "        edge_values = torch.zeros(1)\n",
    "        adj_sparse = torch.sparse_coo_tensor(edge_indices, edge_values, (n_nodes, n_nodes))\n",
    "        print(\"Created empty adjacency matrix\")\n",
    "    \n",
    "    adj_normalized = normalize_adjacency_matrix_sparse(adj_sparse, n_nodes)\n",
    "    \n",
    "    # Prepare labels and temporal masks\n",
    "    labels_map = {'licit': 0, 'illicit': 1, 'unknown': 2}\n",
    "    labels = torch.LongTensor(data_df['class'].map(labels_map).values)\n",
    "    features_tensor = torch.FloatTensor(features)\n",
    "    \n",
    "    # Temporal split: train on timesteps 1-34, test on 35-49\n",
    "    train_mask = torch.BoolTensor(data_df['timestep'] <= 34)\n",
    "    test_mask = torch.BoolTensor(data_df['timestep'] > 34)\n",
    "    \n",
    "    # Filter out 'unknown' classes from training and testing for loss/accuracy calculation\n",
    "    train_mask &= (labels != 2)\n",
    "    test_mask &= (labels != 2)\n",
    "\n",
    "    # --- Model Setup ---\n",
    "    n_features = features_tensor.shape[1]\n",
    "    n_hidden = 100 # As per the paper's hyperparameter tuning\n",
    "    n_classes = 2  # Licit vs Illicit\n",
    "    \n",
    "    model = SkipGCN(n_features=n_features, n_hidden=n_hidden, n_classes=n_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    \n",
    "    # Weighted loss for imbalanced classes (licit vs illicit)\n",
    "    # The paper mentions a 0.3/0.7 weight ratio\n",
    "    loss_weights = torch.FloatTensor([0.3, 0.7])\n",
    "    criterion = nn.NLLLoss(weight=loss_weights)\n",
    "    \n",
    "    # --- Training Loop ---\n",
    "    print(\"Training Skip-GCN model...\")\n",
    "    start_time = time.time()\n",
    "    for epoch in range(200): # The paper trained for 1000 epochs, 200 is good for demonstration\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(features_tensor, adj_normalized)\n",
    "        loss = criterion(output[train_mask], labels[train_mask])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            # Calculate accuracy on the training set for monitoring\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model(features_tensor, adj_normalized).max(1)[1]\n",
    "                correct = pred[train_mask].eq(labels[train_mask]).sum().item()\n",
    "                acc = correct / train_mask.sum().item()\n",
    "                print(f\"Epoch {epoch+1:03d} | Loss: {loss.item():.4f} | Train Acc: {acc:.4f}\")\n",
    "\n",
    "    print(f\"GCN training finished in {time.time() - start_time:.2f} seconds.\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\nEvaluating model performance on the test set...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features_tensor, adj_normalized)\n",
    "        preds = output.max(1)[1]\n",
    "        \n",
    "        test_labels = labels[test_mask].numpy()\n",
    "        test_preds = preds[test_mask].numpy()\n",
    "        \n",
    "        print(\"\\nClassification Report (Test Set):\")\n",
    "        # 0 is licit, 1 is illicit\n",
    "        print(classification_report(test_labels, test_preds, target_names=['Licit', 'Illicit']))\n",
    "\n",
    "        illicit_f1 = f1_score(test_labels, test_preds, pos_label=1)\n",
    "        print(f\"F1 Score for Illicit class: {illicit_f1:.4f}\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    data_df, edgelist_df = load_data()\n",
    "    if data_df is not None:\n",
    "        run_gcn_experiment(data_df, edgelist_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
